---
toc: true
comments: true
layout: post
description: 이산적 값에 대해 연속적인 근사 함수로써, 딥러닝 압축 분야에서 이산적 값에 대한 엔트로피 코딩의 gradient를 계산할 수 있도록 하는 Uniform additive noise 방법에 대하여 서술한다.
categories: [markdown]
title: Uniform additive noise는 무엇이고, 어떻게 동작하는가?
---


## Introduction
- Data Compression에 관한 내용
- Shanon 표현법
- 엔트로피 최소화
- 기존 코덱 방법 동작
- 코딩 (CABAC) 등
- 'zero gradient'

## Optimized End-to-end
- Review (GDN)
- Review (Uniform additive noise)
- Continuously-relaxed loss function
- '당황스럽게 잘 동작'


## Implementation (code)
- tensorflow-compression
- CompressAI

## 코드의 동작법 (트릭)
- Test 시에는 rounding

## Scalable Model Compression 

Linear filters were parameterized using their discrete cosine transform (DCT) coefficients.
We found this to be slightly more effective in speeding up the convergence than discrete
Fourier transform (DFT) parameterization - ICLR'17


---




---
### Related Posts
MPEG 코덱의 미래

### References
{% bibliography --cited %}