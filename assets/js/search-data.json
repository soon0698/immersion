{
  
    
        "post0": {
            "title": "Review - Implicit Neural Representations",
            "content": "Introduction . What is implicit neural representations? . 우리가 처리하는 대부분의 신호는 픽셀 단위의 이미지, 샘플링된 오디오 신호, 그리고 3차원 데이터라 하더라도 통상적으로 복셀(voxel), 포인트 클라우드(point cloud), 메쉬(mesh) 등으로 처리하는게 용이하듯이, 이산적인 신호 표현을 많이 다루게 된다. Implicit Neural Representations 연구에서는 이러한 이산적 신호 표현들을 연속적인 함수로 취급해 다루고자 한다. 그 방법 중 하나는 ‘신호를 mapping할 연속적인 도메인’을 입력으로 받으면, ‘도메인에 해당하는 signal의 값’을 출력하는 함수를 찾는 것이다. 간단히 예를 들어, 이미지를 다루고자 한다면 ‘좌표’를 입력받아서 ‘좌표에 해당하는 이미지의 RGB 값’을 출력하는 함수를 만드는 것이다. 얼핏 생각해보면 이러한 함수는 직접 수식을 일일히 도입하는 수치적 방식으론 풀어낼 수 없는 문제이지만, 뉴럴 네트워크의 강력한 근사능력을 활용하여 ‘그럴듯한’ implicit 함수를 만들어낼 수 있는 시기가 도래한 것이다. . Why are they interesting? . 그렇다면 굳이 그 어려운 문제를, 이산적인 신호를 연속적으로 다루면 어떤 점에서 좋을까? 먼저 한 가지 예시 논문을 들어보자. (Occupancy Networks: Learning 3D Reconstruction in Function Space)에서는 3차원 데이터를 뉴럴 네트워크에 학습해 복원하고자 하는 task를 다룬다. 가장 먼저 직면하는 한 가지 문제점은 3차원 데이터에 대한 메모리와 계산량 문제이다. 복셀(voxel) 표현을 이용할 경우, 256개의 복셀로 이루어진 작은 데이터를 표현하는데에도 $256^{3}$개의 그리드가 필요하며 메모리 측면에서 효율적이라고 볼 수 없다. 포인트 클라우드(point cloud) 표현은 현재까지도 여러 많은 연구가 진행되고 있지만 여전히 데이터 특성상 다루기 어렵고 물체의 boundary 등 structure 정보가 모호한 단점을 갖고 있다. 메쉬(mesh) 표현은 그 특성상 데이터의 표현형이 제한되어있기 때문에 (특히 사람의 얼굴 등) 범용적으로 사용되기가 어렵다. . 이 논문에서는 그렇다면 뉴럴 네트워크가 이 단점들을 모두 해결하는 ‘제 4의 표현을 찾아내줄 수 있을까?’ 라는 질문을 던지고, continuous 3D occupancy function이 실제로 그럴 수 있다는 것을 보이며 occupancy function을 제안한다. . fθ:R3→[0,1]f_{ theta}: mathbb{R}^{3} rightarrow[0,1]fθ​:R3→[0,1] . 그 함수의 동작방식은 충격적으로 단순한데, 3차원 좌표값을 네트워크에게 입력하여 해당 위치의 occupancy probability를 출력하게 한다. 쉽게 말해서, 입력 좌표에 해당하는 위치가 비어있는지 아닌지를 classification하는 쿼리를 학습과정 내내 계속해서 던지는 것이다. 이렇게 단순하게 도식화되면 갑자기 재미난 일들이 일어나기 시작한다. 우선, 입력값인 3차원 좌표 차원 이상의 메모리를 필요로 하지 않게 된다. 게다가 입력 좌표값은 어디까지나 연속적인 도메인이기 때문에, 해상도를 늘리고 줄여도 Implicit 함수의 출력이 어느정도 일관성있게 유지되는 모습을 보인다. 이러한 특징 덕분에 implicit representations는 “infinite resolution”라고도 불린다. . ‘3D 도메인에 강하다’ (memory efficient), https://autonomousvision.github.io/occupancy-networks/ (Learning Shape Templates with Structured Implicit Functions) Vincent Sitzmann[github reference] . 트위터 인용 (https://twitter.com/vincesitzmann/status/1343628606405271554) | Implicit layer와는 다르다 (트위터 논쟁) Implicit | Photometry | Depth map (Stereo) | 기존의 문제 (Low-level 비전 / VAE) | . SIREN . https://twitter.com/vincesitzmann/status/1274119064797888513 https://github.com/bmild/nerf/issues/60 . ‘Implicit neural representation’ 말 자체를 정의한 논문 . F(x,Φ,∇xΦ,∇x2Φ,…)=0,Φ:x↦Φ(x)F left( mathbf{x}, Phi, nabla_{ mathbf{x}} Phi, nabla_{ mathbf{x}}^{2} Phi, ldots right)=0, quad Phi: mathbf{x} mapsto Phi( mathbf{x})F(x,Φ,∇x​Φ,∇x2​Φ,…)=0,Φ:x↦Φ(x) . ‘Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains’ NIPS’20 . 뒤이어 나온 후속논문인 약칭 Fourier Feature Networks에서는 입력 좌표에 대해 간단한 Fourier feature mapping을 해주는 것만으로도 MLP가 다양한 도메인에서 고주파 정보를 잘 습득하게 된다는 점을 밝힌 바 있다. 재미있게도 논문에서는 이렇게 MLP를 이용해 이산적인 신호를 연속함수로 근사하는 Implicit 방법에 대해 “coordinate-based” MLP라고 이름을 새로 붙여주었는데, 네트워크의 입력이 좌표값이 되고 예측값은 그 좌표에 해당하는 결과값(통상적으로 color, density-&gt;NeRF, shape-&gt;occupany network)이 된다는 점에서 더 직관적이고 합당한 이름이라고 생각한다. 논문에서는 제안하는 방법의 타당성을 위해 neural tangent kernel (NTK)의 개념을 활용해 이론적으로도 여러 내용을 제시하여 논문 자체에 담긴 수식들과 그 배경은 꽤 무겁게 느껴지지만, 제안하는 핵심 방법 자체는 코드 한 줄 변경만으로 이루어질 정도로 간단하다.(이는 부록으로 남겨둔다 http://jnwoo.com/post/10/) Coordinate-based MLP 방법론의 기본적인 형태는 입력 좌표 $v$에 대해 다음과 같다: . γ(v)=[cos⁡(2πvv),sin⁡(2πv)]T gamma( mathbf{v})=[ cos (2 pi mathbf{v} v), sin (2 pi mathbf{v})]^{ mathrm{T}}γ(v)=[cos(2πvv),sin(2πv)]T . 제안하는 방법에서는 우리가 예측할 신호에 대한 주파수 스펙트럼의 형태를 정확히 추정할 수 없기 때문에, 단순한 Gaussian 분포 $ mathcal{N} left(0, sigma^{2} right)$에 해당하는 $B$를 도입한다. 이 때, 표준편차는 하이퍼파라미터가 되며 뒤이어 설명하겠지만 안정적인 학습을 위해서는 이 하이퍼파라미터를 잘 결정해주는 게 매우 중요하다. 결과적으로 Fourier Feature Networks의 도입 형태는 다음과 같다: . γ(v)=[cos⁡(2πBv),sin⁡(2πBv)]T gamma( mathbf{v})=[ cos (2 pi mathbf{B} mathbf{v}), sin (2 pi mathbf{B} mathbf{v})]^{ mathrm{T}}γ(v)=[cos(2πBv),sin(2πBv)]T . (PE와의 비교) . 영상 | neural tangent kernel (NTK) | positional encoding | . Nerf . Multiview | Photometry | Depth map (Stereo) | novel view synthesis | 다른 점 강조 (CNN은 공유 가중치, MLP은 fitting) | . Implementation (code) . Code | . . Related Posts . MPEG Immersive Video . References .",
            "url": "https://soon0698.github.io/immersion/markdown/2021/08/15/Nerf.html",
            "relUrl": "/markdown/2021/08/15/Nerf.html",
            "date": " • Aug 15, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Uniform additive noise는 무엇이고, 어떻게 동작하는가?",
            "content": "Introduction . Data Compression에 관한 내용 | Shanon 표현법 | 엔트로피 최소화 | 기존 코덱 방법 동작 | 코딩 (CABAC) 등 | ‘zero gradient’ | . Traditional Video Codec . 주파수 도메인 변환 | 양자화 &amp; 라운딩 | QP 값 | RD-cost tradeoff (Perception tradeoff) | RD plot | . Optimized End-to-end . Review (GDN) | Review (Uniform additive noise) | Continuously-relaxed loss function | ‘당황스럽게 잘 동작’ | 그림 | . Deep Compression . STE . Model Compression through Entropy Penalized Reparameterization The model compression work of Oktay et al. (2020) reparameterizes the model weights Θ into a latent space as Φ. The latent weights are decoded by a learned function F, i.e. Θ = F(Φ). The latent weights Φ are modeled as samples from a learned prior q, such that they can be entropy coded according to this prior. To minimize the rate, i.e. length of the bit string resulting from entropy coding these latent weights, a differentiable approximation of the self-information I(φ) = − log2 (q(φ)) of the latent weights is penalized. The continuous Φ are quantized before being applied in the model, with the straight-through estimator (Bengio et al., 2013) used to obtain surrogate gradients of the loss function. Following Balle et al. (2017), uniform noise is added when learning the continuous prior ´ q(φ + u) where ui ∼ U(− 1 2 , 1 2 ) ∀ i. This uniform noise is a stand-in for the quantization, and results in a good approximation for the self-information through the negative log-likelihood of the noised continuous latent weights. After training, the quantized weights Φ˜ are obtained by rounding, Φ =˜ bΦe, and transmitted along with discrete probability tables obtained by integrating the density over the quantization intervals. The continuous weights Φ and any parameters in q itself can then be discarded . Scalable Model Compression . “Linear filters were parameterized using their discrete cosine transform (DCT) coefficients. We found this to be slightly more effective in speeding up the convergence than discrete Fourier transform (DFT) parameterization - ICLR’17” . (2부?) . Implementation (code) . tensorflow-compression | CompressAI | . 코드의 동작법 (트릭) . Test 시에는 rounding | . . Related Posts . MPEG 코덱의 미래 (2022) . References .",
            "url": "https://soon0698.github.io/immersion/markdown/2021/07/14/Uniform.html",
            "relUrl": "/markdown/2021/07/14/Uniform.html",
            "date": " • Jul 14, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "CS294-158-SP20 Deep Unsupervised Learning Spring 2020 - (1)",
            "content": "본 포스팅은 버클리대학에서 진행된 Deep Unsupervised Learning 강의를 요약하고자 만들어진 포스팅이다. 강의에 대한 모든 자료와 영상은 웹사이트에 공개되어 있으며, 강의자인 Pieter Abbeel은 버클리 인공지능 연구 센터(BAIR)의 디렉터이기도 하다. . Introduction . . What is Unsupervised Learning? . Unsupervised Learning(비지도학습)을 정말 간단히 요약하자면, 가공되지 않은 데이터로부터 패턴을 학습하는 것이다. 기존의 지도학습이 데이터에 대한 정답(라벨)이 미리 요구된다면, 비지도학습은 그런 과정이 필요없는 장점을 갖고 있다. 현재의 비지도학습 방법론은 크게 2가지 범주로 분류할 수 있다. . 생성 모델(Generative Models): 미가공 데이터에 대한 분포를 재구성하는 방법 | . 생성 모델은 학습 데이터의 확률 분포를 학습하게 된다. 일단 이 확률 분포를 학습하여 구성하고나면 기존의 데이터를 분포에 맞추어 생성할 수도 있으며, 분포의 재구성을 통해 새로운 데이터 역시 생성하거나 추론할 수 있다. 이에 대해서는 강의를 진행하며 세부적인 내용들을 다룰 것이다. . 자기지도학습(Self-supervised Learning): 의미있는 정보의 이해가 요구되는 task를 해결하도록 학습하는 방법 | . 자기지도학습은 특정 task를 해결하기 위한 표현을 추출하여 학습한다. 예를 들어 임의로 [0, 90, 180, 270]도씩 회전시킨 이미지를 입력 영상으로 제공하였을 때, 회전된 이미지가 원본 이미지가 되기 위해서는 다시 얼마나 회전시켜야 하는지에 대한 task를 정의하여 task에 필요한 표현을 학습하고자 한 시도가 있다. 이 시도는 매우 간단한 일처럼 보이지만, 사실은 자기지도학습에서 아주 중요하고 심오한 연구 주제로 밝혀진 바 있다. (Gidaris et al., 2018) . Ideal Intelligence . . 비지도학습이 각광받는 이유 중 하나로는 비지도학습이 이상적인 지능(Ideal Intelligence)의 형태에 가장 걸맞는 방법이라는 것이다. 그렇다면 이상적인 지능은 어떤 것을 갖추고 있어야 하는 것일까? 한마디로 정의하자면, 다음과 같다. . “Ideal Intelligence” is all about compression (finding all patterns) . 이상적인 지능은 결국 압축에 관한 것이다. 이 강의에서는 데이터에 내재된 패턴을 찾는 것을 압축과 맞닿아있는 개념으로 본다. 데이터에 내재된 패턴을 이해하고, 이를 더 간결한 형태로 바꿔쓰는 작업이기 때문이다. 이러한 맥락에서, 다음과 같은 수학적 개념들이 제시된다. | . Low Kolmogorov Complexity (short description of raw data) . Kolmogorov Complexity[^2]는 주어진 데이터를 생성할 수 있는 가장 짧은 형태의 표현은 무엇인가? 라는 개념을 제시한다. 가장 짧은 형태의 표현을 찾아낼 수 있다면 우리는 주어진 데이터를 보다 효율적으로 압축할 수 있게 된다. | . Solomonoff Induction (optimal inference) . Solomonoff Induction은 Kolmogorov Complexity의 | . . Related Posts . SyllabusL1 (1/22) IntroductionL2 (1/29) Autoregressive ModelsL3 (2/5) Flow ModelsL4 (2/12) Latent Variable ModelsL5 (2/19) Implicit Models / Generative Adversarial NetworksL6 (2/26) Implicit Models / Generative Adversarial Networks (ctd) + Final Project DiscussionL7 (3/11) Self-Supervised Learning / Non-Generative Representation LearningL8 (3/18) Strengths and Weaknesses of Unsupervised Learning Methods Covered Thus FarL9 (4/1) Semi-Supervised Learning; Unsupervised Distribution AlignmentL10 (4/8) CompressionL11 (4/15) Language Models – Guest Instructor: Alec Radford (OpenAI)L12 (4/29) Representation Learning in Reinforcement Learning . References . Gidaris, S., Singh, P., &amp; Komodakis, N. (2018). Unsupervised Representation Learning by Predicting Image Rotations. |",
            "url": "https://soon0698.github.io/immersion/markdown/2021/02/19/CS294-1.html",
            "relUrl": "/markdown/2021/02/19/CS294-1.html",
            "date": " • Feb 19, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Research",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://soon0698.github.io/immersion/research/",
          "relUrl": "/research/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "About",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://soon0698.github.io/immersion/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  
  

  
  

  
  

  
      ,"page8": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://soon0698.github.io/immersion/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

  
  

}